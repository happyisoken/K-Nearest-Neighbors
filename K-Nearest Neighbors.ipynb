{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c70eab21-4169-472d-b76d-ef21bad87f7b",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbours\n",
    "\n",
    "To understand the k-nearest neighbor algorithm, we first need to understand nearest neighbor. \n",
    "\n",
    "Nearest neighbor algorithm is an algorithm that can be used for regression and classification tasks but is usually used for classification because it is simple and intuitive. A Nearest neighbor classifier has very quick training time as it is just storing all samples. At test time however, its speed is slower because it needs to search through all stored examples for the closest match. The time spent to receive a classification prediction increases as the dataset increases.\n",
    "\n",
    "The k-nearest neighbor algorithm is a modification of the nearest neighbor algorithm in which a class label for an input is voted on by the k closest examples to it. That is the predicted label would be the label with the majority vote from the delegates close to it.\n",
    "\n",
    "##### What is K-Nearest Neighbor (or KNN) Algorithm?\n",
    "\n",
    "The K-Nearest neighbor algorithm is a classification algorithm that takes a bunch of labeled points and uses them to learn how to label other points. \n",
    "- It is a method for classifying cases based on their similarity to other cases. \n",
    "- Data points that are near to each other are said to be neighbors. \n",
    "- It is based on similar cases with same class labels are near each other.\n",
    "\n",
    "#### How K-Nearest Neighbor Algorithm works.\n",
    "1. Pick a value for K.\n",
    "2. Calculate the distance of unknown case from all cases.\n",
    "3. Select the K-observations in the training data that are \"nearest\" to the unknown data point.\n",
    "4. Predict the response of the unknown data point using the most popular response value from the K-nearest neighbors. \n",
    "\n",
    "#### What is the best value of K for KNN?\n",
    "\n",
    "The K in KNN is the number of Nearest Neighbors to examine. It is supposed to be specified by the user.\n",
    "\n",
    "KNN can also be used for regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0b380e-b12a-466e-af65-cbde0c7c9058",
   "metadata": {},
   "source": [
    "#### KNN Algorithm In Machine Learning and KNN Algorithm Using Python\n",
    "\n",
    "KNN is based on feature similarity. We can do classification using KKn classifier.\n",
    "\n",
    "KNN is one of the simplest supervised ML algorithm mostly used for Classification. It classifies a datapoint based on ho its neighbors are classified. It stores all available cases and classifies new cases based on a similarity measure.\n",
    "\n",
    "k in KNN is a parameter that refers to the number of nearest neighbors to include in the majority voting process.\n",
    "A data point is classified by majority votes from its 5 nearest neighbors. \n",
    "\n",
    "##### How do we choose K?\n",
    "KNN Algorithm is based on feature similarity: Choosing the right value of 'k' is a process called parameter tuning, and is important for better accuracy.\n",
    "\n",
    "To choose a value of k:\n",
    "- Sqrt(n), where n is the total number of data points\n",
    "- Odd value of K is selected to avoid confusion between two classes of data.\n",
    "\n",
    "##### When do we use KNN Algorithm?\n",
    "- When data is labeled\n",
    "- When data is noise free\n",
    "- When dataset is small\n",
    "\n",
    "#### How does KNN Algorithm work?\n",
    "- Consider a dataset having two variables: height(cm) & weight(kg) and each point is classified as Normal or Underweight.\n",
    "- On the basis of the given data, we have to classify the below set as Normal or Underweight using KNN.\n",
    "- To find the nearest neighbors, we will calculate Euclidean distance. The Euclidean distance is defined as the distance between two points.\n",
    "- Calculate the nearest neighbor\n",
    "\n",
    "#### Recap of KNN\n",
    "- A positive integer k is specified along with a new sample.\n",
    "- We select the k entries in our database which are closest to the new sample.\n",
    "- We find the most common classification of these entries.\n",
    "- This is the classification we give to the new sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b130e63d-5c14-408e-aafb-f3eae34a2c59",
   "metadata": {},
   "source": [
    "#### Use Case: Predict Diabetes\n",
    "\n",
    "Objective: Predict whether a person will be diagnosed with diabetes or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de6e37da-2af6-4298-b918-50a25e4aedc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required Scikit-learn libraries as shown\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0920c8bb-ff39-4717-8c4e-f83dfede3db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('C:\\\\Users\\\\user\\\\Documents\\\\Data Science Files\\\\Jupyter notebooks for Data Science\\\\diabetes.csv')\n",
    "print( len(dataset) )\n",
    "print( dataset.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8efe06b-fa16-49af-9ad3-1e932b968b03",
   "metadata": {},
   "source": [
    "Values of columns like 'Glucose', BloodPressure' cannot be accepted as zeroes because it will affect the outcome. We can replace such values with the mean of the respective column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a0b3f6d-0acb-43c8-af67-0736e61b324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeroes\n",
    "zero_not_accepted = ['Glucose', 'BloodPressure', 'SkinThickness', 'BMI', 'Insulin']\n",
    "\n",
    "for column in zero_not_accepted:\n",
    "    dataset[column] = dataset[column].replace(0, np.NaN)\n",
    "    mean = int(dataset[column].mean(skipna = True))\n",
    "    dataset[column] = dataset[column].replace(np.NaN, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d4e1dba-e6e3-4eba-96d0-787f612dfc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      148.0\n",
      "1       85.0\n",
      "2      183.0\n",
      "3       89.0\n",
      "4      137.0\n",
      "       ...  \n",
      "763    101.0\n",
      "764    122.0\n",
      "765    121.0\n",
      "766    126.0\n",
      "767     93.0\n",
      "Name: Glucose, Length: 768, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(dataset['Glucose'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4112042d-186e-497e-8bed-7f8db74ced43",
   "metadata": {},
   "source": [
    "Before proceeding further, let's split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37ab2943-ec3c-4883-ae4c-938aedb80648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "X = dataset.iloc[:, 0:8]\n",
    "y = dataset.iloc[:, 8]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886dc7f5-9c98-404f-8084-e73703d90556",
   "metadata": {},
   "source": [
    "Rule of thumb: Any algorithm that computes distance or assumes normality, scale your features - Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8f46517-18db-422c-965d-f2bf2dfce912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eda2d0-63c1-4e8c-95ea-7997d62fcaf0",
   "metadata": {},
   "source": [
    "N_neighbors here is 'K'. p is the power parameter to define the metric used, which is 'Euclidean' in our case. \n",
    "Then define the model using KNeighborsClassifier and fit the train data in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a4befe4-ccac-4028-b676-a4921e63b230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.409673645990857"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sqrt(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4d958e0-8a25-4725-af92-106ade9c9a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model: Init K-NN\n",
    "classifier = KNeighborsClassifier(n_neighbors = 11, p = 2, metric = 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24aa3478-3ff1-443a-9fdf-08a4f49d3637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(metric='euclidean', n_neighbors=11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Model\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "980e14a2-d175-4ba4-acd2-f8533d1badc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caab843b-dd48-4f2d-8c7b-d9188916da7f",
   "metadata": {},
   "source": [
    "It's important to evaluate the model, let's use confusion matrix to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db2aafac-0d9f-49f1-8e7a-690b322cfe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94 13]\n",
      " [15 32]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d875ae54-b326-4b33-a2bf-79fe1c65e1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6956521739130436\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71237221-8cdb-41a9-90b5-98a217aca834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250870ba-0281-4b15-9a55-1767689b1f7e",
   "metadata": {},
   "source": [
    "So, we have created a model using KNN which can predict whether a person will have diabetes or not.\n",
    "An accuracy of 80% tells us that it is a pretty fair fit in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c1632-794b-4b08-a99e-e7e11fdea3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
